#### 4.2.2 Determining the scope of the review

Logic models can vary in their emphasis, with a distinction sometimes made between system-based and process-oriented logic models (Rehfuess et al 2018). System-based logic models have particular value in examining the complexity of the system (e.g. the geographical, epidemiological, political, socio-cultural and socio-economic features of a system), and the interactions between contextual features, participants and the intervention (see Chapter 17). Process-oriented logic models aim to capture the complexity of causal pathways by which the intervention leads to outcomes, and any factors that may modify intervention effects. However, this is not a crisp distinction; the two types are interrelated; with some logic models depicting elements of both systems and process models simultaneously.

The way that logic models can be represented diagrammatically (see Chapter 17 for an example) provides a valuable visual summary for readers and can be a communication tool for decision makers and practitioners. They can aid initially in the development of a shared understanding between different stakeholders of the scope of the review and its PICO, helping to support decisions taken throughout the review process, from developing the research question and setting the review parameters, to structuring and interpreting the results. They can be used in planning the PICO elements of a review as well as for determining how the synthesis will be structured (i.e. planned comparisons, including intervention and comparator groups, and any grouping of outcome and population subgroups). These models may help review authors specify the link between the intervention, proximal and distal outcomes, and mediating factors. In other words, they depict the intervention theory underpinning the synthesis plan.

Anderson and colleagues note the main value of logic models in systematic review as (Anderson et al 2011):

* refining review questions;
* deciding on 'lumping' or'splitting' a review topic;
* identifying intervention components;
* defining and conducting the review;
* identifying relevant study eligibility criteria;
* guiding the literature search strategy;
* explaining the rationale behind surrogate outcomes used in the review;
* justifying the need for subgroup analyses (e.g. age, sex/gender, socio-economic status);
* making the review relevant to policy and practice;
* structuring the reporting of results;
* illustrating how harms and feasibility are connected with interventions; and
* interpreting results based on intervention theory and systems thinking (see Chapter 17).

Logic models can be useful in systematic reviews when considering whether failure to find a beneficial effect of an intervention is due to a theory failure, an implementation failure, or both (see Chapter 17 and Cargo et al 2018). Making a distinction between implementation and intervention theory can help to determine whether and how the intervention interacts with (and potentially changes) its context (see Chapters 3 and 17 for further discussion of context). This helps to elucidate situations in whichvariations in how the intervention is implemented have the potential to affect the integrity of the intervention and intended outcomes.

Given their potential value in conceptualizing and structuring a review, logic models are increasingly published in review protocols. Logic models may be specified a priori and remain unchanged throughout the review; it might be expected, however, that the findings of reviews produce evidence and new understandings that could be used to update the logic model in some way (Kneale et al 2015). Some reviews take a more staged approach, pre-specifying points in the review process where the model may be revised on the basis of (new) evidence (Rehfuess et al 2018) and a staged logic model can provide an efficient way to report revisions to the synthesis plan. For example, in a review of portion, package and tableware size for changing selection or consumption of food and other products, the authors presented a logic model that clearly showed changes to their original synthesis plan (Hollands et al 2015).

It is preferable to seek out existing logic models for the intervention and revise or adapt these models in line with the review focus, although this may not always be possible. More commonly, new models are developed starting with the identification of outcomes and theorizing the necessary pre-conditions to reach those outcomes. This process of theorizing and identifying the steps and necessary pre-conditions continues, working backwards from the intended outcomes, until the intervention itself is represented. As many mechanisms of action are invisible and can only be 'known' through theory, this process is invaluable in exposing assumptions as to how interventions are thought to work; assumptions that might then be tested in the review. Logic models can be developed with stakeholders (see Section 2.5.2) and it is considered good practice to obtain stakeholder input in their development.

Logic models are representations of how interventions are intended to 'work', but they can also provide a useful basis for thinking through the unintended consequences of interventions and identifying potential adverse effects that may need to be captured in the review (Bonell et al 2015). While logic models provide a guiding theory of how interventions are intended to work, critiques exist around their use, including their potential to oversimplify complex intervention processes (Rohwer et al 2017). Here, contributions from different stakeholders to the development of a logic model may be able to articulate where complex processes may occur; theorizing unintended intervention impacts; and the explicit representation of ambiguity within certain parts of the causal chain where new theory/explanation is most valuable.

#### Changing review questions

While questions should be posed in the protocol before initiating the full review, these questions should not prevent exploration of unexpected issues. Reviews are analyses of existing data that are constrained by previously chosen study populations, settings, intervention formulations, outcome measures and study designs. It is generally not possible to formulate an answerable question for a review without knowing some of the studies relevant to the question, and it may become clear that the questions a review addresses need to be modified in light of evidence accumulated in the process of conducting the review.

Although a certain fluidity and refinement of questions is to be expected in reviews as a fuller understanding of the evidence is gained, it is important to guard against bias in modifying questions. Data-driven questions can generate false conclusions based on spurious results. Any changes to the protocol that result from revising the question for the review should be documented in the section 'Differences between the protocol and the review'. Sensitivity analyses may be used to assess the impact of changes on the review findings (see Chapter 10, Section 10.14). When refining questions it is useful to ask the following questions.

* What is the motivation for the refinement?
* Could the refinement have been influenced by results from any of the included studies?
* Does the refined question require a modification to the search strategy and/or reassessment of any decisions regarding study eligibility?
* Are data collection methods appropriate to the refined question?
* Does the refined question still meet the FINER criteria discussed in Section 2.1?

#### 2.5.3 Building in contingencies to deal with sparse data

The ability to address the review questions will depend on the maturity and validity of the evidence base. When few studies are identified, there will be limited opportunity to address the question through an informative synthesis. In anticipation of this scenario, review authors may build contingencies into their protocol analysis plan that specify grouping (any or multiple) PICO elements at a broader level; thus potentially enabling synthesis of a larger number of studies. Broader groupings will generally address a less specific question, for example:

* 'the effect of _any antioxidant supplement_ on...' instead of 'the effect of _vitamin C_ on...';
* 'the effect of sexual health promotion on _biological outcomes_' instead of 'the effect of sexual health promotion on _sexually transmitted infections_'; or
* 'the effect of cognitive behavioural therapy in _children and adolescents_ on...' instead of 'the effect of cognitive behavioural therapy in _children_ on...'.

However, such broader questions may be useful for identifying important leads in areas that lack effective interventions and for guiding future research. Changes in the grouping may affect the assessment of the certainty of the evidence (see Chapter 14).

#### 2.5.4 Economic data

Decision makers need to consider the economic aspects of an intervention, such as whether its adoption will lead to a more efficient use of resources. Economic data such as resource use, costs or cost-effectiveness (or a combination of these) may therefore be included as outcomes in a review. It is useful to break down measures of resource use and costs to the level of specific items or categories. It is helpful to consider an international perspective in the discussion of costs. Economics issues are discussed in detail in Chapter 20.

### Chapter information

**Authors:** James Thomas, Dylan Kneale, Joanne E McKenzie, Sue E Brennan, Soumyadeep Bhaumik

**Acknowledgements:** This chapter builds on earlier versions of the _Handbook_. Mona Nasser, Dan Fox and Sally Crowe contributed to Section 2.4; Hilary J Thomson contributed to Section 2.5.1.

**Funding:** JT and DK are supported by the National Institute for Health Research (NIHR) Collaboration for Leadership in Applied Health Research and Care North Thames at Barts Health NHS Trust. JEM is supported by an Australian National Health and Medical Research Council (NHMRC) Career Development Fellowship (1143429). SEB's position is supported by the NHMRC Cochrane Collaboration Funding Program. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, the Department of Health or the NHMRC.

### References

* Anderson et al. (2011) Anderson L, Petitcrew M, Rehfulness E, Armstrong R, Ueffing E, Baker P, Francis D, Tugwell P. Using logic models to capture complexity in systematic reviews. _Research Synthesis Methods_ 2011; **2**: 33-42.
* Bailey et al. (2010) Bailey JV, Murray E, Rait G, Mercer CH, Morris RW, Peacock R, Cassell J, Nazareth I. Interactive computer-based interventions for sexual health promotion. _Cochrane Database of Systematic Reviews_ 2010; **9**: CD006483.
* Baxter et al. (2014) Baxter SK, Blank L, Woods HB, Payne N, Rimmer M, Goyder E. Using logic model methods in systematic review synthesis: describing complex pathways in referral management interventions. _BMC Medical Research Methodology_ 2014; **14**: 62.
* Bonell et al. (2015) Bonell C, Jamal F, Melendez-Torres GJ, Cummins S. 'Dark logic': theorising the harmful consequences of public health interventions. _Journal of Epidemiology and Community Health_ 2015; **69**: 95-98.
* Bryant et al. (2014) Bryant J, Sanson-Fisher R, Walsh J, Stewart J. Health research priority setting in selected high income countries: a narrative review of methods used and recommendations for future practice. _Cost Effectiveness and Resource Allocation_ 2014; **12**: 23.
* Caldwell and Welton (2016) Caldwell DM, Welton NJ. Approaches for synthesising complex mental health interventions in meta-analysis. _Evidence-Based Mental Health_ 2016; **19**: 16-21.
* Cargo et al. (2018) Cargo M, Harris J, Pantoja T, Booth A, Harden A, Hannes K, Thomas J, Flemming K, Garside R, Noyes J. Cochrane Qualitative and Implementation Methods Group guidance series-paper 4: methods for assessing evidence on intervention implementation. _Journal of Clinical Epidemiology_ 2018; **97**: 59-69.
* Chalmers et al. (2014) Chalmers I, Bracken MB, Djulbegovic B, Garattini S, Grant J, Gulmezoglu AM, Howells DW, Ioannidis JPA, Oliver S. How to increase value and reduce waste when research priorities are set. _Lancet_ 2014; **383**: 156-165.
* Chamberlain et al. (2017) Chamberlain C, O'Mara-Eves A, Porter J, Coleman T, Perlen S, Thomas J, McKenzie J. Psychosocial interventions for supporting women to stop smoking in pregnancy. _Cochrane Database of Systematic Reviews_ 2017; **2**: CD001055.
* CCooper H. The problem formulation stage. In: Cooper H, editor. _Integrating Research: A Guide for Literature Reviews_. Newbury Park (CA) USA: Sage Publications; 1984.
* [1]Counsell C. Formulating questions and locating primary studies for inclusion in systematic reviews. _Annals of Internal Medicine_ 1997; **127**: 380-387.
* [2]Cummings SR, Browner WS, Hulley SB. Conceiving the research question and developing the study plan. In: Hulley SB, Cummings SR, Browner WS, editors. _Designing Clinical Research: An Epidemiological Approach_. 4th ed. Philadelphia (PA): Lippincott Williams & Wilkins; 2007. p. 14-22.
* [3]Glass GV. Meta-analysis at middle age: a personal history. _Research Synthesis Methods_ 2015; **6**: 221-231.
* [4]Hedges LV. Statistical considerations. In: Cooper H, Hedges LV, editors. _The Handbook of Research Synthesis_. New York (NY): USA: Russell Sage Foundation; 1994.
* [5]Hetrick SE, McKenzie JE, Cox GR, Simmons MB, Merry SN. Newer generation antidepressants for depressive disorders in children and adolescents. _Cochrane Database of Systematic Reviews_ 2012; **11**: CD004851.
* [6]Hoffmann T, Glasziou P, Boutron I. Better reporting of interventions: template for intervention description and replication (TIDieR) checklist and guide. _BMJ_ 2014; **348**: g1687.
* [7]Hollands GJ, Shemilt I, Marteau TM, Jebb SA, Lewis HB, Wei Y, Higgins JPT, Ogilvie D. Portion, package or tableware size for changing selection and consumption of food, alcohol and tobacco. _Cochrane Database of Systematic Reviews_ 2015; **9**: CD011045.
* [8]Keown K, Van Eerd D, Irvin E. Stakeholder engagement opportunities in systematic reviews: Knowledge transfer for policy and practice. _Journal of Continuing Education in the Health Professions_ 2008; **28**: 67-72.
* [9]Kneale D, Thomas J, Harris K. Developing and optimising the use of logic models in systematic reviews: exploring practice and good practice in the use of programme theory in reviews. _PloS One_ 2015; **10**: e0142187.
* [10]Lewin S, Hendry M, Chandler J, Oxman AD, Michie S, Shepperd S, Reeves BC, Tugwell P, Hannes K, Rehfuess EA, Welch V, McKenzie JE, Burford B, Petkovic J, Anderson LM, Harris J, Noyes J. Assessing the complexity of interventions within systematic reviews: development, content and use of a new tool (iCAT_SR). _BMC Medical Research Methodology_ 2017; **17**: 76.
* [11]Lorenc T, Petticrew M, Welch V, Tugwell P. What types of interventions generate inequalities? Evidence from systematic reviews. _Journal of Epidemiology and Community Health_ 2013; **67**: 190-193.
* [12]Nasser M, Ueffing E, Welch V, Tugwell P. An equity lens can ensure an equity-oriented approach to agenda setting and priority setting of Cochrane Reviews. _Journal of Clinical Epidemiology_ 2013; **66**: 511-521.
* [13]Nasser M. Setting priorities for conducting and updating systematic reviews [PhD Thesis]: University of Plymouth; 2018.
* [14]O'Neill J, Tabish H, Welch V, Petticrew M, Pottie K, Clarke M, Evans T, Pardo Pardo J, Waters E, White H, Tugwell P. Applying an equity lens to interventions: using PROGRESS ensures consideration of socially stratifying factors to illuminate inequities in health. _Journal of Clinical Epidemiology_ 2014; **67**: 56-64.
* [15]Oliver S, Dickson K, Bangpan M, Newman M. Getting started with a review. In: Gough D, Oliver S, Thomas J, editors. _An Introduction to Systematic Reviews_. London (UK): Sage Publications Ltd.; 2017.
* [16]* [14] Petticrew M, Roberts H. _Systematic Reviews in the Social Sciences: A Practical Guide_. Oxford (UK): Blackwell; 2006.
* [15] Pfadenhauer L, Gerhardus A, Mozygemba K, Lysdahl KB, Booth A, Hofmann B, Wahlster P, Polus S, Burns J, Brereton L, Rehfuess E. Making sense of complexity in context and implementation: the Context and Implementation of Complex Interventions (CICI) framework. _Implementation Science_ 2017; **12**: 21.
* [16] Rehfuess EA, Booth A, Brereton L, Burns J, Gerhardus A, Mozygemba K, Oortwijn W, Pfadenhauer LM, Tummers M, van der Witt GJ, Rohwer A. Towards a taxonomy of logic models in systematic reviews and health technology assessments: a priori, staged, and iterative approaches. _Research Synthesis Methods_ 2018; **9**: 13-24.
* [17] Richardson WS, Wilson MC, Nishikawa J, Hayward RS. The well-built clinical question: a key to evidence-based decisions. _ACP Journal Club_ 1995; **123**: A12-13.
* [18] Rohwer A, Pfadenhauer L, Burns J, Brereton L, Gerhardus A, Booth A, Oortwijn W, Rehfuess E. Series: Clinical epidemiology in South Africa. Paper 3: Logic models help make sense of complexity in systematic reviews and health technology assessments. _Journal of Clinical Epidemiology_ 2017; **83**: 37-47.
* [19] Sharma T, Choudhury M, Rejon-Parrilla JC, Jonsson P, Garner S. Using HTA and guideline development as a tool for research priority setting the NICE way: reducing research waste by identifying the right research to fund. _BMJ Open_ 2018; **8**: e019777.
* [20] Squires J, Valentine J, Grimshaw J. Systematic reviews of complex interventions: framing the review question. _Journal of Clinical Epidemiology_ 2013; **66**: 1215-1222.
* [21] Tong A, Chando S, Crowe S, Manns B, Winkelmayer WC, Hemmelgarn B, Craig JC. Research priority setting in kidney disease: a systematic review. _American Journal of Kidney Diseases_ 2015; **65**: 674-683.
* [22] Tong A, Sautenet B, Chapman JR, Harper C, MacDonald P, Shackel N, Crowe S, Hanson C, Hill S, Synnot A, Craig JC. Research priority setting in organ transplantation: a systematic review. _Transplant International_ 2017; **30**: 327-343.
* [23] Turley R, Saith R, Bhan N, Rehfuess E, Carter B. Slum upgrading strategies involving physical environment and infrastructure interventions and their effects on health and socio-economic outcomes. _Cochrane Database of Systematic Reviews_ 2013; **1**: CD010067.
* [24] van der Heijden I, Abrahams N, Sinclair D. Psychosocial group interventions to improve psychological well-being in adults living with HIV. _Cochrane Database of Systematic Reviews_ 2017; **3**: CD010806.
* [25] Viergever RF. _Health Research Prioritization at WHO: An Overview of Methodology and High Level Analysis of WHO led Health Research Priority Setting Exercises_. Geneva (Switzerland): World Health Organization; 2010.
* [26] Viergever RF, Olifson S, Ghaffar A, Terry RF. A checklist for health research priority setting: nine common themes of good practice. _Health Research Policy and Systems_ 2010; **8**: 36.
* [27] Whitehead M. The concepts and principles of equity and health. _International Journal of Health Services_ 1992; **22**: 429-25.

## 3 Defining the criteria for including studies and how they will be grouped for the synthesis

Joanne E McKenzie, Sue E Brennan, Rebecca E Ryan, Hilary J Thomson,

Renea V Johnston, James Thomas

KEY POINTS

* The scope of a review is defined by the types of population (participants), types of interventions (and comparisons), and the types of outcomes that are of interest. The acronym PICO (population, interventions, comparators and outcomes) helps to serve as a reminder of these.
* The population, intervention and comparison components of the question, with the additional specification of types of study that will be included, form the basis of the pre-specified eligibility criteria for the review. It is rare to use outcomes as eligibility criteria: studies should be included irrespective of whether they _report_ outcome data, but may legitimately be excluded if they do not _measure_ outcomes of interest, or if they explicitly aim to prevent a particular outcome.
* Cochrane Reviews should include all outcomes that are likely to be meaningful and not include trivial outcomes. Critical and important outcomes should be limited in number and include adverse as well as beneficial outcomes.
* Review authors should plan at the protocol stage how the different populations, interventions, outcomes and study designs within the scope of the review will be grouped for analysis.

### Introduction

One of the features that distinguishes a systematic review from a narrative review is that systematic review authors should pre-specify criteria for including and excluding studies in the review (eligibility criteria, see MECIR Box 3.2.a).

When developing the protocol, one of the first steps is to determine the elements of the review question (including the population, intervention(s), comparator(s) andoutcomes, or PICO elements) and how the intervention, in the specified population, produces the expected outcomes (see Chapter 2, Section 2.5.1 and Chapter 17, Section 17.2.1). Eligibility criteria are based on the PICO elements of the review question plus a specification of the types of studies that have addressed these questions. The population, interventions and comparators in the review question usually translate directly into eligibility criteria for the review, though this is not always a straightforward process and requires a thoughtful approach, as this chapter shows. Outcomes usually are not part of the criteria for including studies, and a Cochrane Review would typically seek all sufficiently rigorous studies (most commonly randomized trials) of a particular comparison of interventions in a particular population of participants, irrespective of the outcomes measured or reported. It should be noted that some reviews do legitimately restrict eligibility to specific outcomes. For example, the same intervention may be studied in the same population for different purposes; or a review may specifically address the adverse effects of an intervention used for several conditions (see Chapter 19).

Eligibility criteria do not exist in isolation, but should be specified with the synthesis of the studies they describe in mind. This will involve making plans for how to group variants of the PICO elements for synthesis. This chapter describes the processes by which the structure of the synthesis can be mapped out at the beginning of the review, and the interplay between the review question, considerations for the analysis and their operationalization in terms of eligibility criteria. Decisions about which studies to include (and exclude), and how they will be combined in the review's synthesis, should be documented and justified in the review protocol.

A distinction between three different stages in the review at which the PICO construct might be used is helpful for understanding the decisions that need to be made. In Chapter 2 (Section 2.3) we introduced the ideas of a **review PICO** (on which eligibility of studies is based), the **PICO for each synthesis** (defining the question that each specific synthesis aims to answer) and the **PICO of the included studies** (what was actually investigated in the included studies). In this chapter, we focus on the **review PICO** and the **PICO for each synthesis** as a basis for specifying which studies should be included in the review and planning its syntheses. These PICOs should relate clearly and directly to the questions or hypotheses that are posed when the review is formulated (see Chapter 2) and will involve specifying the population in question, and a set of comparisons between the intervention groups.

An integral part of the process of setting up the review is to specify which characteristics of the interventions (e.g. individual compounds of a drug), populations (e.g. acute and chronic conditions), outcomes (e.g. different depression measurement scales) and study designs, will be grouped together. Such decisions should be made independent of knowing which studies will be included and the methods of synthesis that will be used (e.g. meta-analysis). There may be a need to modify the comparisons and even add new ones at the review stage in light of the data that are collected. For example, important variations in the intervention may be discovered only after data are collected, or modifying the comparison may facilitate the possibility of synthesis when only one or few studies meet the comparison PICO. Planning for the latter scenario at the protocol stage may lead to less post-hoc decision making (Chapter 2, Section 2.5.3) and, of course, any changes made during the conduct of the review should be recorded and documented in the final report.

### 3.2 Articulating the review and comparison PICO

#### 3.2.1 Defining types of participants: which people and populations?

The criteria for considering types of people included in studies in a review should be sufficiently broad to encompass the likely diversity of studies and the likely scenarios in which the interventions will be used, but sufficiently narrow to ensure that a meaningful answer can be obtained when studies are considered together; they should be specified in advance (see MECIR Box 3.2.a). As discussed in Chapter 2 (Section 2.3.1), the degree of breadth will vary, depending on the question being asked and the analytical approach to be employed. A range of evidence may inform the choice of population characteristics to examine, including theoretical considerations, evidence from other interventions that have a similar mechanism of action, and in vitro or animal studies. Consideration should be given to whether the population characteristic is at the level of the participant (e.g. age, severity of disease) or the study (e.g. care setting, geographical

**MECIR Box 3.2.a Relevant expectations for conduct of intervention reviews**

**C5:**: Predefining unambiguous criteria for participants (**Mandatory**)

_Define in advance the eligibility criteria for participants in the studies._

Predefined, unambiguous eligibility

criteria are a fundamental prerequisite

for a systematic review. The criteria for

considering types of people included in

studies in a review should be sufficiently

broad to encompass the likely diversity of

studies, but sufficiently narrow to ensure

that a meaningful answer can be

obtained when studies are considered in

aggregate. Considerations when

specifying participants include setting,

diagnosis or definition of condition and

demographic factors. Any restrictions to

study populations must be based on a

sound rationale, since it is important that

Cochrane Reviews are widely relevant.

**C6:**: Predefining a strategy for studies with a subset of eligible participants (**Highly desirable**)

_Define in advance how studies that include only a subset of relevant participants will be addressed._

Sometimes a study includes some

'eligible' participants and some

'ineligible' participants, for example

when an age cut-off is used in the

review's eligibility criteria. If data from

the eligible participants cannot be

retrieved, a mechanism for dealing with

this situation should be pre-specified.

location), since this has implications for grouping studies and for the method of synthesis (Chapter 10, Section 10.11.5). It is often helpful to consider the types of people that are of interest in three steps.

First, the **diseases or conditions of interest should be defined** using explicit criteria for establishing their presence (or absence). Criteria that will force the unnecessary exclusion of studies should be avoided. For example, diagnostic criteria that were developed more recently - which may be viewed as the current gold standard for diagnosing the condition of interest - will not have been used in earlier studies. Expensive or recent diagnostic tests may not be available in many countries or settings, and time-consuming tests may not be practical in routine healthcare settings.

Second, the **broad population and setting of interest should be defined**. This involves deciding whether a specific population group is within scope, determined by factors such as age, sex, race, educational status or the presence of a particular condition such as angina or shortness of breath. Interest may focus on a particular setting such as a community, hospital, nursing home, chronic care institution, or outpatient setting. Box 3.2.a outlines some factors to consider when developing population criteria.

Whichever criteria are used for defining the population and setting of interest, it is common to encounter studies that only partially overlap with the review's population. For example, in a review focusing on children, a cut-point of less than 16 years might be desirable, but studies may be identified with participants aged from 12 to 18. Unless the study reports separate data from the eligible section of the population (in which case data from the eligible participants can be included in the review), review authors will need a strategy for dealing with these studies (see MECIR Box 3.2.a). This will involve balancing concerns about reduced applicability by including participants who do not meet the eligibility criteria, against the loss of data when studies are excluded. Arbitrary rules (such as including a study if more than 80% of the participants are under 16) will not be practical if detailed information is not available from the study. A less stringent rule, such as 'the majority of participants are under 16' may be sufficient. Although there is a risk of review authors' biases affecting post-hoc inclusion decisions (which is why many authors endeavour to pre-specify these rules), this may be outweighed by a common-sense strategy in which eligibility decisions keep faith with the objectives of the review rather than with arbitrary rules. Difficult decisions should be documented in the review, checked with the advisory group (if available, see Chapter 1), and

* How is the disease/condition defined?
* What are the most important characteristics that describe these people (participants)?
* Are there any relevant demographic factors (e.g. age, sex, ethnicity)?
* What is the setting (e.g. hospital, community, etc)?
* Who should make the diagnosis?
* Are there other types of people who should be excluded from the review (because they are likely to react to the intervention in a different way)?
* How will studies involving only a subset of relevant participants be handled?sensitivity analyses can assess the impact of these decisions on the review's findings (see Chapter 10, Section 10.14 and MECIR Box 3.2.b).

Third, there should be consideration of whether there are **population characteristics that might be expected to modify the size of the intervention effects** (e.g. different severities of heart failure). Identifying subpopulations may be important for implementation of the intervention. If relevant subpopulations are identified, two courses of action are possible: limiting the scope of the review to exclude certain subpopulations; or maintaining the breadth of the review and addressing subpopulations in the analysis.

Restricting the review with respect to specific population characteristics or settings should be based on a sound rationale. It is important that Cochrane Reviews are globally relevant, so the rationale for the exclusion of studies based on population characteristics should be justified. For example, focusing a review of the effectiveness of mammographic screening on women between 40 and 50 years old may be justified based on biological plausibility, previously published systematic reviews and existing controversy. On the other hand, focusing a review on a particular subgroup of people on the basis of their age, sex or ethnicity simply because of personal interests, when there is no underlying biologic or sociological justification for doing so, should be avoided, as these reviews will be less useful to decision makers and readers of the review.

Maintaining the breadth of the review may be best when it is uncertain whether there are important differences in effects among various subgroups of people, since this allows investigation of these differences (see Chapter 10, Section 10.11.5). Review authors may combine the results from different subpopulations in the same synthesis, examining whether a given subdivision explains variation (heterogeneity) among the intervention effects. Alternatively, the results may be synthesized in separate comparisons representing different subpopulations. Splitting by subpopulation risks there being too few studies to yield a useful synthesis (see Table 3.2.a and Chapter 2, Section 2.3.2). Consideration needs to be given to the subgroup analysis method,3 Defining criteria for including studies

\begin{table}
\begin{tabular}{p{56.9pt} p{113.8pt} p{113.8pt}} \hline \hline Population attributes & Examples of population characteristics (and their subpopulations) & Examples of examination of population characteristics in Cochrane Reviews \\ \hline \hline Intended recipient of intervention & Patient, career, healthcare provider (general practitioners, nurses, allied health professionals), health system, policy maker, community & In a review of e-learning programmes for health professionals, a subgroup analysis was planned to examine if the effects were modified by the type of healthcare provider (doctors, nurses or physiotherapists). The authors hypothesized that e-learning programmes for doctors would be more effective than for other health professionals, but did not provide a rationale (Vaona et al 2018). \\ Disease/condition (to be treated or prevented) & Type and severity of a condition & In a review of platelet-rich therapies for musculoskeletal soft tissue injuries, a subgroup analysis was undertaken to examine if the effects of platelet-rich therapies were modified by the type of condition (e.g. rotator cuff tear, anterior cruciate ligament reconstruction, chronic Achilles tendonopathy) (Horcas et al 2014). \\ \hline \hline \end{tabular} In planning a review of beta-blockers for heart failure, subgroup analyses were specified to examine if the effects of beta-blockers are modified by the underlying cause of heart failure (e.g. idiopathic dilated cardiomyopathy, ischaemic heart disease, vehicular heart disease, hypertension) and the severity of heart failure (’reduced left ventricular ejection fraction (LVEF) \(\approx\) 40%, ‘mid-range LVEF \(>\) 40% and \(<\) 50%, ‘preserved LVEF \(\geq\) 50%, ‘mixed, not-specified). Studies have shown that patient characteristics and comorbidities differ by heart failure severity, and that therapies have been shown to reduce morbidity in ‘reduced LVEF’ patients, but the benefits in the other groups are uncertain (Salf et al 2017). \\ Participant characteristics & Age (neonate, child, adolescent, adult, older adult) & In a review of newer-generation antidepressants for depressive disorders in children and adolescents, a subgroup analysis was undertaken to examine if the effects of the antidepressants were modified by age. The rationale was based on the findings of another review that suggested that children and adolescents may respond differently to antidepressants. The age groups were defined as ‘children’ (aged approximately 6 to 12 years), ‘adolescents’ (aged approximately 13 to 18 years), and ‘children’ adolescents’ (when the study included both children and adolescents, and results could not be obtained separately by these subpopulations) (Heitrick et al 2012). \\ Setting & Setting of care (primary care, hospital, community) & In a review of hip protectors for preventing hip fractures in older people, separate comparisons were specified based on setting (institutional care or community-dwelling for the critical outcome of hip fracture (Santesso et al 2014). \\ Setting & Setting of care (primary care, hospital, community) & In a review of hip protectors for preventing hip fractures in older people, separate comparisons were specified based on setting (institutional care or community-dwelling for the critical outcome of hip fracture (Santesso et al 2014). \\ \hline \hline \end{tabular}
\end{table}
Table 3.2.a: Examples of population attributes and characteristicsparticularly for population characteristics measured at the participant level (see Chapters 10 and 26, Fisher et al 2017). All subgroup analyses should ideally be planned a priori and stated as a secondary objective in the protocol, and not driven by the availability of data.

In practice, it may be difficult to assign included studies to defined subpopulations because of missing information about the population characteristic, variability in how the population characteristic is measured across studies (e.g. variation in the method used to define the severity of heart failure), or because the study does not wholly fall within (or report the results separately by) the defined subpopulation. The latter issue mainly applies for participant characteristics but can also arise for settings or geographic locations where these vary within studies. Review authors should consider planning for these scenarios (see example reviews Hetrick et al 2012, Safi et al 2017; Table 3.2.b, column 3).

#### 3.2.2 Defining interventions and how they will be grouped

In some reviews, predefining the intervention (MECIR Box 3.2.c) may be straightforward. For example, in a review of the effect of a given anticoagulant on deep vein thrombosis, the intervention can be defined precisely. A more complicated definition might be required for a multi-component intervention composed of dietary advice, training and support groups to reduce rates of obesity in a given population.

The inherent complexity present when defining an intervention often comes to light when considering how it is thought to achieve its intended effect and whether the effect is likely to differ when variants of the intervention are used. In the first example, the anticoagulant warfarin is thought to reduce blood clots by blocking an enzyme that depends on vitamin K to generate clotting factors. In the second, the behavioural intervention is thought to increase individuals' self-efficacy in their ability to prepare healthy food. In both examples, we cannot assume that all forms of the intervention will work in the same way. When defining drug interventions, such as anticoagulants, factors such as the drug preparation, route of administration, dose, duration, and frequency should be considered. For multi-component interventions (such as interventions to reduce rates of obesity), the common or core features of the interventions must be defined, so that the review authors can clearly differentiate them from other interventions not included in the review.

In general, it is useful to consider **exactly what is delivered, who delivers it, how it is delivered, where it is delivered, when and how much is delivered, and whether the intervention can be adapted or tailored**, and to consider this for each type of intervention included in the review (see the TIDieR checklist (Hoffmann et al 2014)). As argued in Chapter 17, separating interventions into'simple' and 'complex' is a false dichotomy; all interventions can be complex in some ways. The critical issue for review authors is to identify the most important factors to be considered in a specific review. Box 3.2.b outlines some factors to consider when developing broad criteria for the 'Types of interventions' (and comparisons).

Once interventions eligible for the review have been broadly defined, decisions should be made about how variants of the intervention will be handled in the synthesis. Differences in intervention characteristics across studies occur in all reviews. If these reflect minor differences in the form of the intervention used in practice (such as small differences in the duration or content of brief alcohol counselling interventions), then 

#### 3.2.2 The 3 Defining criteria for including studies

#### 3.2.3 The 3 Defining criteria for the 3 Defining criteria

The 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Defining criteria for the 3 Criteria for the 3 Defining criteria for the 3 Criteria for the 3 Defining criteria for the 3 Criteria for the* consider whether a system exists for defining interventions (see Step 3);
* for hard-to-describe groups, provide brief examples of interventions in each group, and
* pilot the criteria to ensure that groups are sufficiently distinct to enable categorization, but not so narrow that interventions are split into many groups, making synthesis impossible (see also Step 4).

Logic models may help structure the synthesis (see Chapter 2, Section 2.4.1 and Chapter 17, Section 17.2.1).

For groups based on 'how much' of an intervention is used (e.g. dose or intensity), criteria are needed to quantify each group. This may be straightforward for easy-to-quantified characteristics, but more complex for characteristics that are hard to quantify (e.g. duration or intensity of rehabilitation or psychological therapy).

The levels should be based on how the intervention is used in practice (e.g. cut-offs for low and high doses of a supplement based on recommended nutrient intake), or on a rationale for how the intervention might work.

In some fields, intervention taxonomies and frameworks have been developed for labelling and describing interventions, and these can make it easier for those using a review to interpret interventions.

Consider this step with step 2a.

Using an agreed system is preferable to developing new groupings. Existing systems should be assessed for relevance and usefulness. The most useful systems:

In reviews of exercise, intensity may be defined by training time (session length, frequency, program duration), amount of work (e.g. repetitions), and effort/energy expenditure (seurtion, heart rate) (Regnaux et al., 2015).

In a review of organized inpatient care for stroke, acute stroke units were categorized as 'intensive','semi-intensive' or 'non-intensive' based on whether the unit had continuous monitoring, high nurse staffing, and life support facilities (Stroke Unit Trialists Collaboration, 2013).

#### 3.2.1 Generic systems

The behaviour change technique (BCT) taxonomy (Michie et al., 2013) categorizes intervention elements such as goal setting, self-monitoring and social support. A protocol for a review of social media interventions used this taxonomy to describe interventions and examine different BCIs as potential effect modifiers (Welch et al, 2018).

* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

Systems for grouping interventions may be generic, widely applicable across clinical areas, or specific to a condition or intervention type. Some Cochrane Groups recommend specific taxonomies.

* 4. Plan how the specified groups will be used in synthesis and reporting.
* [noitemsep,topsep=0pt]
* decide whether it is useful to pool all interventions in a single meta-analysis ["lumping"], within which specific characteristics can be explored as effect modifiers (e.g. in subgroups).
* Alternatively, if pooling all interventions is unlikely to address a useful question, separate synthesis of specific interventions may be more appropriate ("splitting").
* Determining the right analytic approach is discussed further in Chapter 2, Section 2.3.2.
* Some interventions, especially those considered 'complex', including multiple components that could also be implemented independently [12] components might be eligible for inclusion in the review alone, or eligible only if used alongside an eligible intervention.
* Options for considering multi-component interventions may include the following.
* Identifying intervention components for meta-regression or a components-based network meta-analysis [see Chapter 11 and 11], [13], [14].

The _behaviour change wheel_ has been used to group interventions (or components) by function (e.g. to educate, persuade, enable) [10]. This system was used to describe the components of dietary advice interventions [15].

### Specific systems

Multiple reviews have used the consensus-based taxonomy developed by the Prevention of Falls Network Europe (ProFaNE) [e.g. 12, 13]. The taxonomy specifies broad groups (e.g, exercise, medication, environment/assistive technology) within which are more specific groups (e.g. exercise: gait, balance and functional training, flexibility, strength and resistance) [10].

In a review of exercise for knee osteoarthritis, the different categories of exercise were combined in a single meta-analysis, addressing the question 'what is the effect of exercise on knee osteoarthritis?'. The categories were also analysed as subgroups within the meta-analysis to explore whether the effect size varied by type of exercise [14]. Other subgroup analyses examined mode of delivery and dose.

### Grouping by main component:

In a review of psychological therapies for panic disorder, two of the eight eligible therapies (psycholactuation and supportive psychotherapy) could be used alone or as part of a multi-component therapy. When accompanied by another eligible therapy, the intervention was categorized as the other therapy (i.e. psychoeducation + cognitive behavioural therapy was categorized as cognitive behavioural therapy) [16, 17].

### Separate group:

In a review of psychosocial interventions for smoking cessation in pregnancy, two approaches were used. All intervention types were included in a single meta-analysis

\begin{table}
\begin{tabular}{p{142.3pt} p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & The _behaviour change wheel_ has been used to group interventions (or components) by function (e.g. to educate, persuade, enable) [10]. This system was used to describe the components of dietary advice interventions [15].

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* are developed systematically and based on consensus, preferably with stakeholders including clinicians, patients, policy makers, and researchers, and
* have been validated through successful use in a range of applications (ideally, including in systematic reviews).

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Step & Considerations & Examples \\ \hline \hline \end{tabular}
* use terminology that is understood by those using or implementing the intervention;
* Grouping based on the'main' intervention component (Caldwell and Welton, 2016).
* Specifying a separate group ('multi-component interventions'). 'Lumping' multi-component interventions together may provide information about their effects in general; however, this approach may lead to unexplained heterogeneity and/or inability to identify which components are effective (Caldwell and Welton, 2016).
* Reporting results study by study. An option if components are expected to be so diverse that synthesis will not be interpretable.
* Excluding multi-component interventions. An option if the effect of the intervention of interest cannot be discerned. This approach may reduce the relevance of the review. The first two approaches may be challenging but are likely to be most useful (Caldwell and Welton, 2016).
* See Section 3.2.3.1. for the special case of when a co-intervention is administered in both treatment arms.
* Consider grouping interventions at more than one level, so by specifying both specific and broader intervention groups.
* Consider grouping interventions at more than one level, so that studies of a broader group of interventions can be synthesized if two few studies are identified for synthesis in more specific groups. This will provide flexibility where review authors anticipate few studies contributing to specific groups (e.g. in reviews with diverse interventions, additional diversity in other PICO elements, or few studies overall, see also Chapter 2, Section 2.5.3.

with subgroups for multi-component, single and tailored interventions. Separate meta-analyses were also performed for each intervention type, with categorization of multi-component interventions based on the'main' component (Chamberlain et al, 2017).

In a review of psychosocial interventions for smoking cessation, the authors planned to group any psychosocial intervention in a single comparison (addressing the higher level question of whether, on average, psychosocial interventions are effective). Given that sufficient data were available, they also presented separate meta-analyses to examine the effects of specific types of psychosocial interventions (e.g. counselling, health education, incentives, social support) (Chamberlain et al, 2017).

**MECIR Box 3.2.c Relevant expectations for conduct of intervention reviews**

_C7:_ Predefining unambiguous criteria for interventions and comparators (**Mandatory**)

_Define in advance the eligible interventions and the interventions against which these can be compared in the included studies._ Predefined, unambiguous eligibility criteria are a fundamental prerequisite for a systematic review. Specification of comparator interventions requires particular clarity: are the experimental interventions to be compared with an inactive control intervention (e.g. placebo, no treatment, standard care, or a waiting list control), or with an active control intervention (e.g. a different variant of the same intervention, a different drug, a different kind of therapy)? Any restrictions on interventions and comparators, for example, regarding delivery, dose, duration, intensity, co-interventions and features of complex interventions should also be predefined and explained.

**Box 3.2.b Factors to consider when developing criteria for 'Types of interventions'**

* What are the experimental and control (comparator) interventions of interest?
* Does the intervention have variations (e.g. dosage/intensity, mode of delivery, personnel who deliver it, frequency, duration or timing of delivery)?
* Are all variations to be included (for example, is there a dose below which the intervention may not be clinically appropriate, will all providers be included)?
* Will studies including only part of the intervention be included?
* Will studies including the intervention of interest combined with another intervention (co-intervention) be included?
* Have the different meanings of phrases such as 'control', 'placebo', 'no intervention' or 'usual care' been considered?

an overall synthesis can provide useful information for decision makers. Where differences in intervention characteristics are more substantial (such as delivery of brief alcohol counselling by nurses versus doctors), and are expected to have a substantial impact on the size of intervention effects, these differences should be examined in the synthesis. What constitutes an important difference requires judgement, but in general differences that alter decisions about how an intervention is implemented or whether the intervention is used or not are likely to be important. In such circumstances, review authors should consider specifying separate groups (or subgroups) to examine in their synthesis.

#### 3.2.3 Calculating the review and comparison PICO

Clearly defined intervention groups serve two main purposes in the synthesis. First, the way in which interventions are grouped for synthesis (meta-analysis or other synthesis) is likely to influence review findings. Careful planning of intervention groups makes best use of the available data, avoids decisions that are influenced by study findings (which may introduce bias), and produces a review focused on questions relevant to decision makers. Second, the intervention groups specified in a protocol provide a standardized terminology for describing the interventions throughout the review, overcoming the varied descriptions used by study authors (e.g. where different labels are used for the same intervention, or similar labels used for different techniques) (Michie et al 2013). This standardization enables comparison and synthesis of information about intervention characteristics across studies (common characteristics and differences) and provides a consistent language for reporting that supports interpretation of review findings.

Table 3.2.b outlines a process for planning intervention groups as a basis for/precursor to synthesis, and the decision points and considerations at each step. The table is intended to guide, rather than to be prescriptive and, although it is presented as a sequence of steps, the process is likely to be iterative, and some steps may be done concurrently or in a different sequence. The process aims to minimize data-driven approaches that can arise once review authors have knowledge of the findings of the included studies. It also includes principles for developing a flexible plan that maximizes the potential to synthesize in circumstances where there are few studies, many variants of an intervention, or where the variants are difficult to anticipate. In all stages, review authors should consider how to categorize studies whose reports contain insufficient detail.

#### 3.2.3 Defining which comparisons will be made

When articulating the PICO for each synthesis, defining the intervention groups alone is not sufficient for complete specification of the planned syntheses. The next step is to define the comparisons that will be made between the intervention groups. Setting aside for a moment more complex analyses such as network meta-analyses, which can simultaneously compare many groups (Chapter 11), standard meta-analysis (Chapter 10) aims to draw conclusions about the comparative effects of two groups at a time (i.e. which of two intervention groups is more effective?). These comparisons form the basis for the syntheses that will be undertaken if data are available. Cochrane Reviews sometimes include one comparison, but most often include multiple comparisons. Three commonly identified types of comparisons include the following (Davey et al 2011).

* Intervention versus placebo (e.g. placebo drug, sham surgical procedure, psychological placebo). Placebos are most commonly used in the evaluation of pharmacological interventions, but may be also be used in some non-pharmacological evaluations. For example:
* newer generation antidepressants versus placebo (Hetrick et al 2012); and
* vertebplasty for osteoporotic vertebral compression fractures versus placebo (sham procedure) (Buchbinder et al 2018).
* Intervention versus control (e.g. no intervention, wait-list control, usual care). Both intervention arms may also receive standard therapy. For example:* chemotherapy or targeted therapy plus best supportive care (BSC) versus BSC for palliative treatment of esophageal and gastroesophageal-junction carcinoma (Janmaat et al, 2017); and
* personalized care planning versus usual care for people with long-term conditions (Coulter et al, 2015).
* Intervention A versus intervention B. A comparison of active interventions may include comparison of the same intervention delivered at different time points, for different lengths of time or different doses, or two different interventions. For example:
* early (commenced at less than two weeks of age) versus late (two weeks of age or more) parenteral zinc supplementation in term and preterm infants (Taylor et al, 2017);
* high intensity versus low intensity physical activity or exercise in people with hip or knee osteoarthritis (Regnaux et al, 2015);
* multimedia education versus other education for consumers about prescribed and over the counter medications (Ciciriello et al, 2013).

The first two types of comparisons aim to establish the effectiveness of an intervention, while the last aims to compare the effectiveness of two interventions. However, the distinction between the placebo and control is often arbitrary, since any differences in the care provided between trials with a control arm and those with a placebo arm may be unimportant, especially where 'usual care' is provided to both. Therefore, placebo and control groups may be determined to be similar enough to be combined for synthesis.

In reviews including multiple intervention groups, many comparisons are possible. In some of these reviews, authors seek to synthesize evidence on the comparative effectiveness of all their included interventions, including where there may be only indirect comparison of some interventions across the included studies (Chapter 11, Section 11.2.1). However, in many reviews including multiple intervention groups, a limited subset of the possible comparisons will be selected. The chosen subset of comparisons should address the most important clinical and research questions. For example, if an established intervention (or dose of an intervention) is used in practice, then the synthesis would ideally compare novel or alternative interventions to this established intervention, and not, for example, to no intervention.

##### 3.2.3.1 Dealing with co-interventions

Planning is needed for the special case where the _same_ supplementary intervention is delivered to both the intervention and comparator groups. A supplementary intervention is an additional intervention delivered alongside the intervention of interest, such as massage in a review examining the effects of aromatherapy (i.e. aromatherapy plus massage versus massage alone). In many cases, the supplementary intervention will be unimportant and can be ignored. In other situations, the effect of the intervention of interest may differ according to whether participants receive the supplementary therapy. For example, the effect of aromatherapy among people who receive a massage may differ from the effect of the aromatherapy given alone. This will be the case if the intervention of interest interacts with the supplementary intervention leading to larger (synergistic) or smaller (dys synergistic/antagonistic) effects than the intervention of interest alone (Squires et al 2013). While qualitative interactions are rare (where the effect of the intervention is in the opposite direction when combined with the supplementary intervention), it is possible that there will be more variation in the intervention effects (heterogeneity) when supplementary interventions are involved, and it is important to plan for this. Approaches for dealing with this in the statistical synthesis may include fitting a random-effects meta-analysis model that encompasses heterogeneity (Chapter 10, Section 10.10.4), or investigating whether the intervention effect is modified by the addition of the supplementary intervention through subgroup analysis (Chapter 10, Section 10.11.2).

#### Selecting, prioritizing and grouping review outcomes

##### 3.2.4.1 Selecting review outcomes

Broad outcome domains are decided at the time of setting up the review PICO (see Chapter 2). Once the broad domains are agreed, further specification is required to define the domains to facilitate reporting and synthesis (i.e. the PICO for each synthesis) (see Chapter 2, Section 2.3). The process for specifying and grouping outcomes largely parallels that used for specifying intervention groups.

**Reporting of outcomes should rarely determine study eligibility for a review.** In particular, studies should not be excluded because they do not report results of an outcome they may have measured, or provide 'no usable data' (MECIR Box 3.2.d). This is essential to avoid bias arising from selective reporting of findings by the study authors (see Chapter 13). However, in some circumstances, the measurement of certain outcomes may be a study eligibility criterion. This may be the case, for example, when the review addresses the

MECIR Box 3.2.d Relevant expectations for conduct of intervention reviews

_C8:_ Clarifying role of outcomes (**Mandatory**)

_Clarify in advance whether outcomes listed under 'Criteria for considering studies for this review' are used as criteria for including studies (rather than as a list of the outcomes of interest within whichever studies are included)._ Outcome measures should not always form part of the criteria for including studies in a review. However, some reviews do legitimately restrict eligibility to specific outcomes. For example, the same intervention may be studied in the same population for different purposes (e.g. hormone replacement therapy, or aspirin); or a review may address specifically the adverse effects of an intervention used for several conditions. If authors do exclude studies on the basis of outcomes, care should be taken to ascertain that relevant outcomes are not available because they have not been measured rather than simply not reported.

_C14:_ Predefining outcome domains (**Mandatory**)

_Define in advance outcomes that are critical to the review, and any additional important outcomes._

Full specification of the outcomes

includes consideration of outcome

domains (e.g. quality of life) and outcome

measures (e.g. SF-36). Predefinition of

outcome reduces the risk of selective

outcome reporting. The _critical outcomes_

should be as few as possible and should

normally reflect at least one potential

benefit and at least one potential area of

harm. It is expected that the review

should be able to synthesize these

outcomes if eligible studies are identified,

and that the conclusions of the review

will be based largely on the effects of the

interventions on these outcomes.

Additional important outcomes may also be specified. Up to seven critical and

important outcomes will form the basis

of the GRADE assessment and

summarized in the review's abstract and

other summary formats, although the

review may measure more than seven

outcomes.

Cochrane Reviews are intended to

support clinical practice and policy, and

should address outcomes that are critical

or important to consumers. These should

be specified at protocol stage. Where

available, established sets of core

outcomes should be used. Patient-

reported outcomes should be included

where possible. It is also important to

judge whether evidence of resource use

and costs might be an important

component of decisions to adopt the

intervention or alternative management

strategies around the world. Large

numbers of outcomes, while sometimes

necessary, can make reviews unfocused,

unmanageable for the user, and prone to

selective outcome reporting bias.

potential for an intervention to _prevent_ a particular outcome, or when the review addresses a specific purpose of an intervention that can be used in the same population for different purposes (such as hormone replacement therapy, or aspirin).

In general, systematic reviews should aim to **include outcomes that are likely to be meaningful to the intended users and recipients of the reviewed evidence.** This may include clinicians, patients (consumers), the general public, administrators and policy makers. Outcomes may include survival (mortality), clinical events (e.g. strokes or myocardial infarction), behavioural outcomes (e.g. changes in diet, use of services), patient-reported outcomes (e.g. symptoms, quality of life), adverse events, burdens (e.g. demands on caregivers, frequency of tests, restrictions on lifestyle) and economic outcomes (e.g. cost and resource use). It is critical that outcomes used to assess adverse effects as well as outcomes used to assess beneficial effects are among those addressed by a review (see Chapter 19).

Outcomes that are trivial or meaningless to decision makers should not be included in Cochrane Reviews. Inclusion of outcomes that are of little or no importance risks overwhelming and potentially misleading readers. Interim or surrogate outcomes measures, such as laboratory results or radiologic results (e.g. loss of bone mineral content as a surrogate for fractures in hormone replacement therapy), while potentially helpful in explaining effects or determining intervention integrity (see Chapter 5, Section 5.3.4.1), can also be misleading since they may not predict clinically important outcomes accurately. Many interventions reduce the risk for a surrogate outcome but have no effect or have harmful effects on clinically relevant outcomes, and some interventions have no effect on surrogate measures but improve clinical outcomes.

Various sources can be used to develop a list of relevant outcomes, including input from consumers and advisory groups (see Chapter 2), the clinical experiences of the review authors, and evidence from the literature (including qualitative research about outcomes important to those affected (see Chapter 21)). A further driver of outcome selection is consideration of outcomes used in related reviews. Harmonization of outcomes across reviews addressing related questions facilitates broader evidence synthesis questions being addressed through the use of Overviews of reviews (see online Chapter V).

Outcomes considered to be meaningful, and therefore addressed in a review, may not have been reported in the primary studies. For example, quality of life is an important outcome, perhaps the most important outcome, for people considering whether or not to use chemotherapy for advanced cancer, even if the available studies are found to report only survival (see Chapter 18). A further example arises with timing of the outcome measurement, where time points determined as clinically meaningful in a review are not measured in the primary studies. Including and discussing all important outcomes in a review will highlight gaps in the primary research and encourage researchers to address these gaps in future studies.

##### Prioritizing review outcomes

Once a full list of relevant outcomes has been compiled for the review, authors should prioritize the outcomes and select the outcomes of most relevance to the review question. The GRADE approach to assessing the certainty of evidence (see Chapter 14) suggests that review authors separate outcomes into those that are 'critical', 'important' and 'not important' for decision making.

The critical outcomes are the essential outcomes for decision making, and are those that would form the basis of a 'Summary of findings' table or other summary versions of the review, such as the Abstract or Plain Language Summary. 'Summary of findings' tables provide key information about the amount of evidence for important comparisons and outcomes, the quality of the evidence and the magnitude of effect (see Chapter 14, Section 14.1). There should be no more than seven outcomes included in a 'Summary of findings' table, and those outcomes that will be included in summaries should be specified at the protocol stage. They should generally not include surrogate or interim outcomes. They should not be chosen on the basis of any anticipated or observed magnitude of effect, or because they are likely to have been addressed in the studies to be reviewed. Box 3.2.c summarizes the principal factors to consider when selecting and prioritizing review outcomes.

**Box 3.2.c**: **Factors to consider when selecting and prioritizing review outcomes**

* Consider outcomes relevant to all potential decision makers.
* Critical outcomes are those that are essential for decision making, and should usually have an emphasis on patient-important outcomes and be determined by core outcomes sets.
* Additional outcomes important to decision makers may also be included in the review. Any outcomes not considered important to decision makers should be excluded from the review.
* Up to seven critical and important outcomes should be selected for inclusion in summary versions of the review, including 'Summary of findings' tables, Abstracts and Plain Language Summaries. Remember that summaries may be read alone, and should include the most important outcomes for decision makers.
* Ensure that outcomes cover potential as well as actual adverse effects.

#### 3.2.4.3 Defining and grouping outcomes for synthesis

Table 3.2.c outlines a process for planning for the diversity in outcome measurement that may be encountered in the studies included in a review and which can complicate, and sometimes prevent, synthesis. Research has repeatedly documented inconsistency in the outcomes measured across trials in the same clinical areas (Harrison et al 2016, Williamson et al 2017). This inconsistency occurs across all aspects of outcome measurement, including the broad domains considered, the outcomes measured, the way these outcomes are labelled and defined, and the methods and timing of measurement. For example, a review of outcome measures used in 563 studies of interventions for dementia and mild cognitive impairment found that 321 unique measurement methods were used for 1278 assessments of cognitive outcomes (Harrison et al 2016). Initiatives like COMET (Core Outcome Measures in Effectiveness Trials) aim to encourage standardization of outcome measurement across trials (Williamson et al 2017), but these initiatives are comparatively new and review authors will inevitably encounter diversity in outcomes across studies.

The process begins by describing the scope of each outcome domain in sufficient detail to enable outcomes from included studies to be categorized (Table 3.2.c Step 1). This step may be straightforward in areas for which core outcome sets (or equivalent systems) exist (Table 3.2.c Step 2). The methods and timing of outcome measurement also need to be specified, giving consideration to how differences across studies will be handled (Table 3.2.c Steps 3 and 4). Subsequent steps consider options for dealing with studies that report multiple measures within an outcome domain (Table 3.2.c Step 5), planning how outcome domains will be used in synthesis (Table 3.2.c Step 6), and building in contingencies to maximize potential to synthesize (Table 3.2.c Step 7).

### 3.3 Determining which study designs to include

Some study designs are more appropriate than others for answering particular questions. Authors need to consider a priori what study designs are likely to provide reliable data with which to address the objectives of their review (MECIR Box 3.3.a). Sections 3.3.1 and 3.3.2 cover randomized and non-randomized designs for assessing treatment effects; Chapter 17 (Section 17.2.5) discusses other study designs in the context of addressing intervention complexity.

#### 3.3.1 Including randomized trials

Because Cochrane Reviews address questions about the effects of health care, they focus primarily on randomized trials and randomized trials should be included if they are feasible for the interventions of interest (MECIR Box 3.3.b). Randomization is the only way to prevent systematic differences between baseline characteristics of participants in different intervention groups in terms of both known and unknown (or unmeasured) confounders (see Chapter 8), and claims about cause and effect can be based on their findings with far more confidence than almost any other type of study. For clinical interventions, deciding who receives an intervention and who does not is influenced by many factors, including prognostic factors. Empirical evidence